import openai
from core.vector_store_compatible import vector_store
from config.settings import settings
from typing import Dict, List
import time
import json

class SimpleRAGChain:
    """ç®€åŒ–çš„RAGé—®ç­”é“¾æ¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–RAGé“¾æ¡"""
        self.client = openai.OpenAI(
            api_key=settings.OPENAI_API_KEY,
            base_url=settings.OPENAI_API_BASE
        )
        
        # æç¤ºæ¨¡æ¿
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIåŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚

è¯·éµå¾ªä»¥ä¸‹è¦æ±‚ï¼š
1. åªåŸºäºæä¾›çš„æ–‡æ¡£å†…å®¹å›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
2. å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·æ˜ç¡®è¯´æ˜
3. å›ç­”è¦ç®€æ´æ˜äº†ï¼Œçªå‡ºé‡ç‚¹
4. å¯ä»¥é€‚å½“å¼•ç”¨æ–‡æ¡£ä¸­çš„åŸæ–‡

ç›¸å…³æ–‡æ¡£å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·æä¾›å‡†ç¡®ã€æœ‰ç”¨çš„å›ç­”ï¼š"""
    
    def calculate_confidence(self, source_docs, question, answer):
        """æ”¹è¿›çš„ç½®ä¿¡åº¦è®¡ç®—"""
        if not source_docs:
            return 0.1
        
        # 1. åŸºç¡€åˆ†æ•°ï¼šåŸºäºæ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡
        doc_score = min(len(source_docs) / settings.TOP_K, 1.0) * 0.4
        
        # 2. ç›¸å…³æ€§åˆ†æ•°ï¼šåŸºäºæ–‡æ¡£å†…å®¹ä¸é—®é¢˜çš„åŒ¹é…åº¦
        relevance_score = 0
        question_words = set(question.lower().split())
        
        for doc in source_docs:
            doc_words = set(doc.page_content.lower().split())
            # è®¡ç®—è¯æ±‡é‡å åº¦
            if question_words and doc_words:
                overlap = len(question_words & doc_words) / len(question_words | doc_words)
                relevance_score += overlap
        
        relevance_score = min(relevance_score / len(source_docs), 1.0) * 0.3 if source_docs else 0
        
        # 3. ç­”æ¡ˆé•¿åº¦åˆ†æ•°ï¼šå¤ªçŸ­çš„ç­”æ¡ˆå¯èƒ½ä¸å¤Ÿè¯¦ç»†
        answer_length_score = min(len(answer.split()) / 50, 1.0) * 0.2
        
        # 4. å…³é”®è¯åŒ¹é…åˆ†æ•°ï¼šç­”æ¡ˆæ˜¯å¦åŒ…å«é—®é¢˜ä¸­çš„å…³é”®è¯
        keyword_score = 0
        for word in question_words:
            if len(word) > 2 and word in answer.lower():
                keyword_score += 1
        keyword_score = min(keyword_score / max(len(question_words), 1), 1.0) * 0.1
        
        total_confidence = doc_score + relevance_score + answer_length_score + keyword_score
        
        return min(max(total_confidence, 0.1), 0.95)  # é™åˆ¶åœ¨0.1-0.95ä¹‹é—´
    
    def ask(self, question: str) -> Dict:
        """æé—®å¹¶è·å–ç­”æ¡ˆ"""
        print(f"ğŸ¤” ç”¨æˆ·é—®é¢˜: {question}")
        
        start_time = time.time()
        
        try:
            # 1. æ£€ç´¢ç›¸å…³æ–‡æ¡£
            print("æ­£åœ¨æ£€ç´¢ç›¸å…³æ–‡æ¡£...")
            source_docs = vector_store.similarity_search(question, k=settings.TOP_K)
            
            # 2. æ„å»ºä¸Šä¸‹æ–‡
            context_parts = []
            citations = []
            
            for i, doc in enumerate(source_docs):
                context_parts.append(f"æ–‡æ¡£ç‰‡æ®µ {i+1}:\n{doc.page_content}")
                
                citations.append({
                    "chunk_id": i,
                    "content": doc.page_content[:200] + "..." if len(doc.page_content) > 200 else doc.page_content,
                    "source": doc.metadata.get("source_file", "unknown"),
                    "chunk_index": doc.metadata.get("chunk_id", i)
                })
            
            context = "\n\n".join(context_parts)
            
            # 3. æ„å»ºå®Œæ•´æç¤º
            full_prompt = self.system_prompt.format(
                context=context,
                question=question
            )
            
            print(f"æ„å»ºä¸Šä¸‹æ–‡å®Œæˆï¼Œä½¿ç”¨äº† {len(source_docs)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
            
            # 4. è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
            print(" æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
            response = self.client.chat.completions.create(
                model=settings.MODEL_NAME,
                messages=[
                    {"role": "user", "content": full_prompt}
                ],
                temperature=0.1,
                max_tokens=1000
            )
            
            answer = response.choices[0].message.content
            
            # 5. è®¡ç®—å“åº”æ—¶é—´
            response_time = time.time() - start_time
            
            # 6. è®¡ç®—ç½®ä¿¡åº¦
            confidence = self.calculate_confidence(source_docs, question, answer)
            
            # 7. è·å–tokenä½¿ç”¨é‡
            tokens_used = response.usage.total_tokens if hasattr(response, 'usage') else None
            
            result_dict = {
                "question": question,
                "answer": answer,
                "citations": citations,
                "confidence": confidence,
                "response_time": response_time,
                "source_count": len(source_docs),
                "tokens_used": tokens_used
            }
            
            print(f"å›ç­”ç”Ÿæˆå®Œæˆ")
            print(f"æ€»è€—æ—¶: {response_time:.2f} ç§’")
            print(f"ä½¿ç”¨äº† {len(source_docs)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")
            if tokens_used:
                print(f"æ¶ˆè€— tokens: {tokens_used}")
            
            return result_dict
            
        except Exception as e:
            print(f"é—®ç­”å¤±è´¥: {e}")
            return {
                "question": question,
                "answer": f"æŠ±æ­‰ï¼Œå›ç­”é—®é¢˜æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}",
                "citations": [],
                "confidence": 0.0,
                "response_time": time.time() - start_time,
                "source_count": 0,
                "tokens_used": 0
            }
    
    def interactive_chat(self):
        """äº¤äº’å¼èŠå¤©æ¨¡å¼"""
        print(" RAGåŠ©æ‰‹å·²å¯åŠ¨ï¼è¾“å…¥ 'quit' é€€å‡º")
        print("-" * 50)
        
        while True:
            try:
                question = input("\nğŸ‘¤ æ‚¨çš„é—®é¢˜: ").strip()
                
                if question.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("å†è§ï¼")
                    break
                
                if not question:
                    continue
                
                result = self.ask(question)
                print(f"\n å›ç­”: {result['answer']}")
                print(f"ç½®ä¿¡åº¦: {result['confidence']:.2f}")
                
                if result['citations']:
                    print("\nå‚è€ƒæ–‡æ¡£:")
                    for i, citation in enumerate(result['citations'], 1):
                        print(f"   {i}. {citation['content']}")
                
            except KeyboardInterrupt:
                print("\nå†è§ï¼")
                break
            except Exception as e:
                print(f"å‡ºç°é”™è¯¯: {e}")

# åˆ›å»ºå…¨å±€RAGé“¾æ¡å®ä¾‹
rag_chain = SimpleRAGChain()
