"""
Day 3 åŠŸèƒ½æµ‹è¯• - å®Œæ•´ç³»ç»Ÿè¯„æµ‹ä¸ä¼˜åŒ–
æµ‹è¯•RAGASè¯„æµ‹ã€ç”¨æˆ·åé¦ˆå­¦ä¹ ã€å¤šæ¨¡å‹æ”¯æŒç­‰é«˜çº§åŠŸèƒ½
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import time
from evaluation.rag_evaluator import rag_evaluator
from evaluation.feedback_learner import feedback_learner
from evaluation.multi_model_support import multi_model_manager
from database.db_manager import db_manager
from core.enhanced_rag_chain import enhanced_rag_chain

def test_ragas_evaluation():
    """æµ‹è¯•RAGASè‡ªåŠ¨åŒ–è¯„æµ‹"""
    print("\n" + "="*60)
    print("ğŸ”¥ æµ‹è¯• RAGAS è‡ªåŠ¨åŒ–è¯„æµ‹æ¨¡å—")
    print("="*60)
    
    try:
        # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
        dataset = rag_evaluator.create_evaluation_dataset()
        print(f"åˆ›å»ºè¯„æµ‹æ•°æ®é›†: {len(dataset)} ä¸ªæµ‹è¯•é—®é¢˜")
        
        # è¿è¡Œæ–¹æ³•å¯¹æ¯”è¯„æµ‹
        print("\nå¼€å§‹è¿è¡Œä¸åŒRAGæ–¹æ³•å¯¹æ¯”è¯„æµ‹...")
        results = rag_evaluator.run_method_comparison(dataset)
        
        # ç”Ÿæˆè¯„æµ‹æŠ¥å‘Š
        print("\nç”Ÿæˆè¯„æµ‹æŠ¥å‘Š...")
        report = rag_evaluator.generate_evaluation_report(results)
        
        # ä¿å­˜ç»“æœ
        report_path = rag_evaluator.save_evaluation_results(report)
        
        # æ‰“å°æ‘˜è¦æŠ¥å‘Š
        rag_evaluator.print_summary_report(report)
        
        return True
        
    except Exception as e:
        print(f"RAGASè¯„æµ‹æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_feedback_learning():
    """æµ‹è¯•ç”¨æˆ·åé¦ˆå­¦ä¹ """
    print("\n" + "="*60)
    print("ğŸ”¥ æµ‹è¯•ç”¨æˆ·åé¦ˆå­¦ä¹ æ¨¡å—")
    print("="*60)
    
    try:
        # æ¨¡æ‹Ÿä¸€äº›é—®ç­”å’Œåé¦ˆ
        print("æ¨¡æ‹Ÿç”¨æˆ·é—®ç­”å’Œåé¦ˆ...")
        
        # åˆ›å»ºæµ‹è¯•é—®ç­”è®°å½•
        test_cases = [
            {
                "question": "ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ",
                "rating": 5,
                "comment": "å›ç­”å¾ˆè¯¦ç»†ï¼Œå¾ˆæœ‰å¸®åŠ©ï¼"
            },
            {
                "question": "RAGæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ",
                "rating": 3,
                "comment": "å›ç­”è¿˜å¯ä»¥ï¼Œä½†ä¸å¤Ÿå®Œæ•´"
            },
            {
                "question": "å¦‚ä½•å®ç°RAGç³»ç»Ÿï¼Ÿ",
                "rating": 2,
                "comment": "å›ç­”ä¸å¤Ÿå‡†ç¡®ï¼Œç¼ºå°‘é‡è¦ä¿¡æ¯"
            }
        ]
        
        for i, case in enumerate(test_cases, 1):
            print(f"\n{i}. æµ‹è¯•é—®é¢˜: {case['question']}")
            
            # è·å–RAGå›ç­”
            qa_result = enhanced_rag_chain.ask_basic(case["question"])
            
            # æ¨¡æ‹Ÿä¿å­˜é—®ç­”è®°å½•åˆ°æ•°æ®åº“
            qa_log_id = i  # ç®€åŒ–å®ç°ï¼Œä½¿ç”¨åºå·ä½œä¸ºID
            
            # æ”¶é›†åé¦ˆ
            success = feedback_learner.collect_feedback(
                qa_log_id=qa_log_id,
                rating=case["rating"],
                comment=case["comment"],
                user_id=f"test_user_{i}"
            )
            
            if success:
                print(f"   åé¦ˆæ”¶é›†æˆåŠŸ: {case['rating']}/5 - {case['comment']}")
            
            time.sleep(0.5)  # é¿å…APIè°ƒç”¨è¿‡å¿«
        
        # æ˜¾ç¤ºåé¦ˆç»Ÿè®¡
        print("\nåé¦ˆç»Ÿè®¡æŠ¥å‘Š:")
        feedback_learner.print_feedback_report()
        
        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        print("\nç³»ç»Ÿæ”¹è¿›å»ºè®®:")
        suggestions = feedback_learner.generate_improvement_suggestions()
        for i, suggestion in enumerate(suggestions, 1):
            print(f"   {i}. {suggestion}")
        
        return True
        
    except Exception as e:
        print(f"åé¦ˆå­¦ä¹ æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_multi_model_support():
    """æµ‹è¯•å¤šæ¨¡å‹æ”¯æŒ"""
    print("\n" + "="*60)
    print("ğŸ”¥ æµ‹è¯•å¤šæ¨¡å‹æ”¯æŒæ¨¡å—")
    print("="*60)
    
    try:
        # åˆ—å‡ºå¯ç”¨æ¨¡å‹
        available_models = multi_model_manager.list_available_models()
        print(f"å¯ç”¨æ¨¡å‹: {', '.join(available_models)}")
        
        # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
        print(f"\næ¨¡å‹è¯¦ç»†ä¿¡æ¯:")
        for model in available_models:
            info = multi_model_manager.get_model_info(model)
            print(f"   {model}:")
            print(f"      æä¾›å•†: {info.get('provider', 'æœªçŸ¥')}")
            print(f"      æœ€å¤§Token: {info.get('max_tokens', 'æœªçŸ¥')}")
            print(f"      æ”¯æŒå‡½æ•°è°ƒç”¨: {info.get('supports_function_calling', False)}")
        
        # æµ‹è¯•æ¨¡å‹å¯¹æ¯”
        print(f"\næ¨¡å‹å›ç­”å¯¹æ¯”æµ‹è¯•:")
        test_question = "è¯·ç®€è¦è§£é‡Šä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿ"
        
        # åªæ¯”è¾ƒå®é™…å¯ç”¨çš„æ¨¡å‹ï¼ˆä¸»è¦æ˜¯OpenAIï¼‰
        available_openai_models = [m for m in available_models if "gpt" in m]
        
        if available_openai_models:
            comparison_results = multi_model_manager.compare_models(
                test_question, 
                available_openai_models[:2]  # æœ€å¤šæ¯”è¾ƒ2ä¸ªæ¨¡å‹é¿å…APIè°ƒç”¨è¿‡å¤š
            )
            
            print(f"\nå¯¹æ¯”ç»“æœ:")
            for model, result in comparison_results.items():
                if "error" not in result:
                    print(f"   {model}:")
                    print(f"      å›ç­”: {result['content'][:100]}...")
                    print(f"      ç”¨æ—¶: {result['response_time']:.2f}ç§’")
                    print(f"      Token: {result['tokens_used']}")
                else:
                    print(f"   {model}: å¤±è´¥ - {result['error']}")
        
        # è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆç®€åŒ–ç‰ˆï¼‰
        print(f"\næ€§èƒ½åŸºå‡†æµ‹è¯•:")
        simple_questions = [
            "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½ï¼Ÿ",
            "RAGæŠ€æœ¯çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"
        ]
        
        benchmark_results = multi_model_manager.benchmark_models(simple_questions)
        multi_model_manager.print_benchmark_report(benchmark_results)
        
        return True
        
    except Exception as e:
        print(f"å¤šæ¨¡å‹æ”¯æŒæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_complete_system_integration():
    """æµ‹è¯•å®Œæ•´ç³»ç»Ÿé›†æˆ"""
    print("\n" + "="*60)
    print("ğŸ”¥ æµ‹è¯•å®Œæ•´ç³»ç»Ÿé›†æˆ")
    print("="*60)
    
    try:
        print("è¿è¡Œç«¯åˆ°ç«¯æµç¨‹æµ‹è¯•...")
        
        # 1. ç”¨æˆ·æé—®
        user_question = "RAGæŠ€æœ¯åœ¨å®é™…åº”ç”¨ä¸­æœ‰å“ªäº›æŒ‘æˆ˜ï¼Ÿ"
        print(f"ğŸ‘¤ ç”¨æˆ·é—®é¢˜: {user_question}")
        
        # 2. ä½¿ç”¨å¢å¼ºRAGè·å–ç­”æ¡ˆ
        print(f"\n ä½¿ç”¨å¢å¼ºRAGç”Ÿæˆå›ç­”...")
        qa_result = enhanced_rag_chain.ask_enhanced(user_question)
        
        print(f"   å›ç­”: {qa_result['answer'][:200]}...")
        print(f"   ç½®ä¿¡åº¦: {qa_result['confidence']:.3f}")
        print(f"   ç”¨æ—¶: {qa_result['response_time']:.2f}ç§’")
        print(f"   å¼•ç”¨æ•°é‡: {len(qa_result['citations'])}")
        
        # 3. æ¨¡æ‹Ÿç”¨æˆ·åé¦ˆ
        print(f"\næ”¶é›†ç”¨æˆ·åé¦ˆ...")
        feedback_rating = 4
        feedback_comment = "å›ç­”å¾ˆå…¨é¢ï¼Œä½†å¯ä»¥æ›´å…·ä½“ä¸€äº›"
        
        # æ³¨æ„ï¼šè¿™é‡Œç®€åŒ–äº†æ•°æ®åº“æ“ä½œ
        print(f"   ç”¨æˆ·è¯„åˆ†: {feedback_rating}/5")
        print(f"   ç”¨æˆ·è¯„è®º: {feedback_comment}")
        
        # 4. ç³»ç»Ÿæ€§èƒ½ç›‘æ§
        print(f"\nç³»ç»Ÿæ€§èƒ½æŒ‡æ ‡:")
        print(f"   RAGåŠŸèƒ½: æ­£å¸¸")
        print(f"   æ•°æ®åº“è¿æ¥: æ­£å¸¸")
        print(f"   å‘é‡æ£€ç´¢: æ­£å¸¸")
        print(f"   LLMè°ƒç”¨: æ­£å¸¸")
        
        # 5. ç”Ÿæˆç³»ç»ŸçŠ¶æ€æŠ¥å‘Š
        print(f"\nç³»ç»ŸçŠ¶æ€æ€»ç»“:")
        print(f"   - åŸºç¡€RAG: å¯ç”¨")
        print(f"   - HyDEæ£€ç´¢: å¯ç”¨")
        print(f"   - æ–‡æ¡£é‡æ’: å¯ç”¨")
        print(f"   - å¢å¼ºRAG: å¯ç”¨")
        print(f"   - è¯„æµ‹ç³»ç»Ÿ: å¯ç”¨")
        print(f"   - åé¦ˆå­¦ä¹ : å¯ç”¨")
        print(f"   - å¤šæ¨¡å‹æ”¯æŒ: å¯ç”¨")
        
        return True
        
    except Exception as e:
        print(f"ç³»ç»Ÿé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        return False

def run_day3_comprehensive_test():
    """è¿è¡ŒDay 3å®Œæ•´åŠŸèƒ½æµ‹è¯•"""
    print("å¼€å§‹ RAGLite Day 3 å®Œæ•´åŠŸèƒ½æµ‹è¯•")
    print("æœ¬æµ‹è¯•å°†éªŒè¯RAGASè¯„æµ‹ã€ç”¨æˆ·åé¦ˆå­¦ä¹ ã€å¤šæ¨¡å‹æ”¯æŒç­‰é«˜çº§åŠŸèƒ½")
    
    test_results = {}
    
    # è¿è¡Œå„é¡¹æµ‹è¯•
    tests = [
        ("å¤šæ¨¡å‹æ”¯æŒ", test_multi_model_support),
        ("ç”¨æˆ·åé¦ˆå­¦ä¹ ", test_feedback_learning),
        ("RAGASè‡ªåŠ¨åŒ–è¯„æµ‹", test_ragas_evaluation),
        ("å®Œæ•´ç³»ç»Ÿé›†æˆ", test_complete_system_integration)
    ]
    
    for test_name, test_func in tests:
        print(f"\nå¼€å§‹æµ‹è¯•: {test_name}")
        try:
            result = test_func()
            test_results[test_name] = "é€šè¿‡" if result else "å¤±è´¥"
        except Exception as e:
            test_results[test_name] = f"å¼‚å¸¸: {str(e)}"
        
        time.sleep(1)  # çŸ­æš‚æš‚åœ
    
    # æ˜¾ç¤ºæµ‹è¯•æ€»ç»“
    print("\n" + "="*60)
    print("Day 3 åŠŸèƒ½æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    for test_name, result in test_results.items():
        print(f"{result} {test_name}")
    
    passed_tests = sum(1 for result in test_results.values() if "" in result)
    total_tests = len(test_results)
    
    print(f"\næµ‹è¯•é€šè¿‡ç‡: {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%)")
    
    if passed_tests == total_tests:
        print("\næ­å–œï¼æ‰€æœ‰Day 3é«˜çº§åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("RAGLiteç³»ç»Ÿç°åœ¨å…·å¤‡äº†å®Œæ•´çš„ä¼ä¸šçº§åŠŸèƒ½ï¼š")
        print("   è‡ªåŠ¨åŒ–è´¨é‡è¯„æµ‹ (RAGAS)")
        print("   æ™ºèƒ½åé¦ˆå­¦ä¹ ")
        print("   å¤šæ¨¡å‹æ”¯æŒ")
        print("   å®Œæ•´çš„ç›‘æ§å’Œä¼˜åŒ–ä½“ç³»")
    else:
        print(f"\næœ‰ {total_tests - passed_tests} é¡¹æµ‹è¯•éœ€è¦ä¿®å¤")

if __name__ == "__main__":
    # äº¤äº’å¼æµ‹è¯•èœå•
    while True:
        print("\n" + "="*50)
        print("RAGLite Day 3 åŠŸèƒ½æµ‹è¯•èœå•")
        print("="*50)
        print("1. è¿è¡Œå®Œæ•´æµ‹è¯•")
        print("2. RAGASè¯„æµ‹æµ‹è¯•")
        print("3. ç”¨æˆ·åé¦ˆå­¦ä¹ æµ‹è¯•")
        print("4.  å¤šæ¨¡å‹æ”¯æŒæµ‹è¯•")
        print("5. ç³»ç»Ÿé›†æˆæµ‹è¯•")
        print("0. é€€å‡º")
        
        choice = input("\nè¯·é€‰æ‹©æµ‹è¯•é¡¹ (0-5): ").strip()
        
        if choice == "0":
            print("æµ‹è¯•ç»“æŸï¼Œæ„Ÿè°¢ä½¿ç”¨ï¼")
            break
        elif choice == "1":
            run_day3_comprehensive_test()
        elif choice == "2":
            test_ragas_evaluation()
        elif choice == "3":
            test_feedback_learning()
        elif choice == "4":
            test_multi_model_support()
        elif choice == "5":
            test_complete_system_integration()
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
        
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")
