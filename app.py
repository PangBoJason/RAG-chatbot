"""
RAGLite - æ™ºèƒ½é—®ç­”åŠ©æ‰‹ (å®Œæ•´ç‰ˆ)
é›†æˆäº†RAGASè¯„æµ‹ã€ç”¨æˆ·åé¦ˆå­¦ä¹ ã€å¤šæ¨¡å‹æ”¯æŒç­‰ä¼ä¸šçº§åŠŸèƒ½
"""
import streamlit as st
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import time
import json
import tempfile
from core.enhanced_rag_chain import enhanced_rag_chain
from core.document_loader import document_loader
from core.vector_store_compatible import vector_store
from database.db_manager import db_manager
from evaluation.rag_evaluator import rag_evaluator
from evaluation.feedback_learner import feedback_learner
from evaluation.multi_model_support import multi_model_manager
from config.settings import settings

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="RAGLite - æ™ºèƒ½é—®ç­”åŠ©æ‰‹",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

def initialize_session_state():
    """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
    if 'session_id' not in st.session_state:
        st.session_state.session_id = db_manager.create_conversation("streamlit_user")
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'selected_model' not in st.session_state:
        st.session_state.selected_model = "gpt-3.5-turbo"
    if 'rag_method' not in st.session_state:
        st.session_state.rag_method = "enhanced"

def upload_and_process_file(uploaded_file):
    """ä¸Šä¼ å’Œå¤„ç†æ–‡ä»¶"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp_file:
        tmp_file.write(uploaded_file.getvalue())
        tmp_file_path = tmp_file.name
    
    try:
        # å¤„ç†æ–‡æ¡£
        chunks = document_loader.process_document(tmp_file_path)
        
        if chunks:
            # å‘é‡åŒ–å­˜å‚¨
            vector_ids = vector_store.add_documents(chunks)
            
            # è®°å½•åˆ°æ•°æ®åº“
            metadata = {
                "filename": uploaded_file.name,
                "file_size": len(uploaded_file.getvalue()),
                "chunks_count": len(chunks),
                "upload_time": time.time()
            }
            
            db_manager.add_document_metadata(
                filename=uploaded_file.name,
                content_hash=str(hash(uploaded_file.getvalue())),
                metadata=json.dumps(metadata)
            )
            
            return len(chunks)
        else:
            return 0
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(tmp_file_path):
            os.unlink(tmp_file_path)

def display_chat_interface():
    """æ˜¾ç¤ºèŠå¤©ç•Œé¢"""
    st.header("æ™ºèƒ½é—®ç­”")
    
    # RAGæ–¹æ³•é€‰æ‹©
    col1, col2 = st.columns([2, 1])
    
    with col1:
        rag_method = st.selectbox(
            "é€‰æ‹©RAGæ–¹æ³•",
            ["basic", "hyde", "rerank", "enhanced"],
            index=["basic", "hyde", "rerank", "enhanced"].index(st.session_state.rag_method),
            format_func=lambda x: {
                "basic": "åŸºç¡€RAG",
                "hyde": "HyDEå¢å¼º",
                "rerank": "é‡æ’åºRAG",
                "enhanced": "å¢å¼ºRAG (æ¨è)"
            }[x]
        )
        st.session_state.rag_method = rag_method
    
    with col2:
        if st.button("æ–¹æ³•å¯¹æ¯”", help="æ¯”è¾ƒä¸åŒRAGæ–¹æ³•çš„è¡¨ç°"):
            st.session_state.show_comparison = True
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    chat_container = st.container()
    
    with chat_container:
        for message in st.session_state.chat_history:
            with st.chat_message(message["role"]):
                if message["role"] == "assistant":
                    st.write(message["content"])
                    
                    # æ˜¾ç¤ºç½®ä¿¡åº¦
                    if "confidence" in message:
                        confidence = message["confidence"]
                        confidence_color = "é«˜" if confidence > 0.8 else "ä¸­" if confidence > 0.6 else "ä½"
                        st.caption(f"{confidence_color} ç½®ä¿¡åº¦: {confidence:.3f}")
                    
                    # æ˜¾ç¤ºå¼•ç”¨
                    if "citations" in message and message["citations"]:
                        with st.expander("å‚è€ƒæ–‡æ¡£"):
                            for i, citation in enumerate(message["citations"], 1):
                                st.write(f"**å¼•ç”¨ {i}:** {citation['content'][:200]}...")
                                if citation.get('similarity'):
                                    st.caption(f"ç›¸ä¼¼åº¦: {citation['similarity']:.3f}")
                    
                    # åé¦ˆæ”¶é›†
                    feedback_key = f"feedback_{len(st.session_state.chat_history)}_{message.get('timestamp', 0)}"
                    col1, col2, col3 = st.columns([1, 2, 1])
                    
                    with col2:
                        rating = st.select_slider(
                            "è¯„ä»·å›ç­”è´¨é‡",
                            options=[1, 2, 3, 4, 5],
                            value=3,
                            format_func=lambda x: str(x) + "æ˜Ÿ",
                            key=feedback_key
                        )
                        
                        feedback_comment = st.text_input(
                            "åé¦ˆæ„è§ (å¯é€‰)",
                            placeholder="è¯·åˆ†äº«æ‚¨çš„æƒ³æ³•...",
                            key=f"comment_{feedback_key}"
                        )
                        
                        if st.button("æäº¤åé¦ˆ", key=f"submit_{feedback_key}"):
                            # è¿™é‡Œç®€åŒ–äº†åé¦ˆæ”¶é›†æµç¨‹
                            st.success(f"æ„Ÿè°¢æ‚¨çš„åé¦ˆï¼è¯„åˆ†: {rating}/5")
                            if feedback_comment:
                                st.info(f"åé¦ˆ: {feedback_comment}")
                
                else:
                    st.write(message["content"])
    
    # è¾“å…¥æ¡†
    if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # ç”¨æˆ·æ¶ˆæ¯
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.write(prompt)
        
        # AIå›ç­”
        with st.chat_message("assistant"):
            with st.spinner("æ€è€ƒä¸­..."):
                # æ ¹æ®é€‰æ‹©çš„æ–¹æ³•è·å–å›ç­”
                if rag_method == "basic":
                    result = enhanced_rag_chain.ask_basic(prompt)
                elif rag_method == "hyde":
                    result = enhanced_rag_chain.ask_hyde(prompt)
                elif rag_method == "rerank":
                    result = enhanced_rag_chain.ask_rerank(prompt)
                else:  # enhanced
                    result = enhanced_rag_chain.ask_enhanced(prompt)
                
                # æ˜¾ç¤ºå›ç­”
                st.write(result["answer"])
                
                # æ˜¾ç¤ºç½®ä¿¡åº¦
                confidence = result["confidence"]
                confidence_color = "é«˜" if confidence > 0.8 else "ä¸­" if confidence > 0.6 else "ä½"
                st.caption(f"{confidence_color} ç½®ä¿¡åº¦: {confidence:.3f} | ç”¨æ—¶: {result['response_time']:.2f}ç§’")
                
                # æ˜¾ç¤ºå¼•ç”¨
                if result["citations"]:
                    with st.expander(f"å‚è€ƒæ–‡æ¡£ ({len(result['citations'])} ä¸ª)"):
                        for i, citation in enumerate(result["citations"], 1):
                            st.write(f"**å¼•ç”¨ {i}:** {citation['content'][:200]}...")
                            if citation.get('similarity'):
                                st.caption(f"ç›¸ä¼¼åº¦: {citation['similarity']:.3f}")
                
                # ä¿å­˜åˆ°èŠå¤©å†å²
                assistant_message = {
                    "role": "assistant",
                    "content": result["answer"],
                    "confidence": confidence,
                    "citations": result["citations"],
                    "response_time": result["response_time"],
                    "timestamp": time.time()
                }
                st.session_state.chat_history.append(assistant_message)
                
                # è®°å½•åˆ°æ•°æ®åº“
                db_manager.add_qa_log(
                    session_id=st.session_state.session_id,
                    question=prompt,
                    answer=result["answer"],
                    confidence=confidence,
                    response_time=result["response_time"],
                    context=json.dumps([c["content"] for c in result["citations"]])
                )

def display_comparison_interface():
    """æ˜¾ç¤ºæ–¹æ³•å¯¹æ¯”ç•Œé¢"""
    if st.session_state.get('show_comparison', False):
        st.header("RAGæ–¹æ³•å¯¹æ¯”")
        
        test_question = st.text_input(
            "è¾“å…¥æµ‹è¯•é—®é¢˜",
            value="ä»€ä¹ˆæ˜¯RAGæŠ€æœ¯ï¼Ÿå®ƒæœ‰ä»€ä¹ˆä¼˜åŠ¿ï¼Ÿ",
            help="è¾“å…¥ä¸€ä¸ªé—®é¢˜æ¥æ¯”è¾ƒä¸åŒRAGæ–¹æ³•çš„è¡¨ç°"
        )
        
        if st.button("å¼€å§‹å¯¹æ¯”"):
            methods = {
                "åŸºç¡€RAG": enhanced_rag_chain.ask_basic,
                "HyDEå¢å¼º": enhanced_rag_chain.ask_hyde,
                "é‡æ’åºRAG": enhanced_rag_chain.ask_rerank,
                "å¢å¼ºRAG": enhanced_rag_chain.ask_enhanced
            }
            
            comparison_results = {}
            
            progress_bar = st.progress(0)
            
            for i, (method_name, method_func) in enumerate(methods.items()):
                with st.spinner(f"æµ‹è¯• {method_name}..."):
                    result = method_func(test_question)
                    comparison_results[method_name] = result
                    progress_bar.progress((i + 1) / len(methods))
            
            # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
            st.subheader("å¯¹æ¯”ç»“æœ")
            
            for method_name, result in comparison_results.items():
                with st.expander(f"{method_name} - ç½®ä¿¡åº¦: {result['confidence']:.3f}"):
                    st.write("**å›ç­”:**")
                    st.write(result["answer"])
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ç½®ä¿¡åº¦", f"{result['confidence']:.3f}")
                    with col2:
                        st.metric("å“åº”æ—¶é—´", f"{result['response_time']:.2f}s")
                    with col3:
                        st.metric("å¼•ç”¨æ•°é‡", len(result["citations"]))
                    
                    if result["citations"]:
                        st.write("**å‚è€ƒæ–‡æ¡£:**")
                        for i, citation in enumerate(result["citations"][:2], 1):
                            st.write(f"{i}. {citation['content'][:100]}...")
        
        if st.button("å…³é—­å¯¹æ¯”"):
            st.session_state.show_comparison = False
            st.rerun()

def display_document_management():
    """æ˜¾ç¤ºæ–‡æ¡£ç®¡ç†ç•Œé¢"""
    st.header("æ–‡æ¡£ç®¡ç†")
    
    # æ–‡æ¡£ä¸Šä¼ 
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ æ–‡æ¡£",
        type=['txt', 'pdf', 'docx', 'md'],
        help="æ”¯æŒTXTã€PDFã€DOCXã€Markdownæ ¼å¼"
    )
    
    if uploaded_file is not None:
        if st.button("ğŸ“¥ å¤„ç†æ–‡æ¡£"):
            with st.spinner("å¤„ç†æ–‡æ¡£ä¸­..."):
                chunks_count = upload_and_process_file(uploaded_file)
                
                if chunks_count > 0:
                    st.success(f"æ–‡æ¡£å¤„ç†å®Œæˆï¼å…±ç”Ÿæˆ {chunks_count} ä¸ªæ–‡æœ¬å—")
                else:
                    st.error("æ–‡æ¡£å¤„ç†å¤±è´¥")
    
    # æ˜¾ç¤ºå·²ä¸Šä¼ çš„æ–‡æ¡£
    st.subheader("å·²ä¸Šä¼ æ–‡æ¡£")
    
    documents = db_manager.get_document_stats()
    
    if documents:
        for doc in documents:
            with st.expander(f"{doc.filename}"):
                metadata = json.loads(doc.metadata) if doc.metadata else {}
                
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"**æ–‡ä»¶å¤§å°:** {metadata.get('file_size', 'N/A')} å­—èŠ‚")
                    st.write(f"**æ–‡æœ¬å—æ•°:** {metadata.get('chunks_count', 'N/A')}")
                
                with col2:
                    upload_time = metadata.get('upload_time')
                    if upload_time:
                        st.write(f"**ä¸Šä¼ æ—¶é—´:** {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(upload_time))}")
    else:
        st.info("æš‚æ— å·²ä¸Šä¼ çš„æ–‡æ¡£")

def display_evaluation_panel():
    """æ˜¾ç¤ºè¯„æµ‹é¢æ¿"""
    st.header("ç³»ç»Ÿè¯„æµ‹")
    
    tab1, tab2, tab3 = st.tabs(["RAGASè¯„æµ‹", "ç”¨æˆ·åé¦ˆ", " å¤šæ¨¡å‹æ”¯æŒ"])
    
    with tab1:
        st.subheader("RAGASè‡ªåŠ¨åŒ–è¯„æµ‹")
        
        if st.button("è¿è¡Œè¯„æµ‹"):
            with st.spinner("è¿è¡ŒRAGASè¯„æµ‹ä¸­..."):
                try:
                    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
                    dataset = rag_evaluator.create_evaluation_dataset()
                    
                    # è¿è¡Œè¯„æµ‹
                    results = rag_evaluator.run_method_comparison(dataset)
                    
                    # ç”ŸæˆæŠ¥å‘Š
                    report = rag_evaluator.generate_evaluation_report(results)
                    
                    # æ˜¾ç¤ºç»“æœ
                    st.subheader("è¯„æµ‹ç»“æœ")
                    
                    # æ–¹æ³•æ’å
                    st.write("**æ–¹æ³•æ’å:**")
                    for rank, (method, score) in enumerate(report['overall_ranking'], 1):
                        st.write(f"{rank}. {method.upper()}: {score:.3f}")
                    
                    # è¯¦ç»†æŒ‡æ ‡
                    st.write("**è¯¦ç»†æŒ‡æ ‡:**")
                    for method, perf in report['method_performance'].items():
                        metrics = perf['metrics']
                        
                        with st.expander(f"{method.upper()} æ–¹æ³•"):
                            col1, col2, col3, col4 = st.columns(4)
                            
                            with col1:
                                st.metric("å¿ å®åº¦", f"{metrics['avg_faithfulness']:.3f}")
                            with col2:
                                st.metric("ç›¸å…³æ€§", f"{metrics['avg_relevance']:.3f}")
                            with col3:
                                st.metric("å®Œæ•´æ€§", f"{metrics['avg_completeness']:.3f}")
                            with col4:
                                st.metric("ç»¼åˆåˆ†", f"{metrics['avg_overall_score']:.3f}")
                
                except Exception as e:
                    st.error(f"è¯„æµ‹å¤±è´¥: {e}")
    
    with tab2:
        st.subheader("ç”¨æˆ·åé¦ˆåˆ†æ")
        
        # æ˜¾ç¤ºåé¦ˆç»Ÿè®¡
        stats = feedback_learner.get_feedback_statistics()
        
        if stats.get("total_feedback", 0) > 0:
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æ€»åé¦ˆæ•°", stats["total_feedback"])
            with col2:
                st.metric("å¹³å‡è¯„åˆ†", f"{stats['average_rating']:.2f}/5")
            with col3:
                st.metric("æ»¡æ„åº¦", f"{stats['satisfaction_rate']:.1f}%")
            with col4:
                st.metric("ä½è¯„åˆ†æ•°", stats["low_rating_count"])
            
            # è¯„åˆ†åˆ†å¸ƒ
            st.write("**è¯„åˆ†åˆ†å¸ƒ:**")
            rating_data = []
            for rating in range(1, 6):
                count = stats['rating_distribution'].get(rating, 0)
                rating_data.append({"è¯„åˆ†": f"{rating}æ˜Ÿ", "æ•°é‡": count})
            
            st.bar_chart({item["è¯„åˆ†"]: item["æ•°é‡"] for item in rating_data})
            
            # æ”¹è¿›å»ºè®®
            suggestions = feedback_learner.generate_improvement_suggestions()
            if suggestions:
                st.write("**æ”¹è¿›å»ºè®®:**")
                for suggestion in suggestions:
                    st.write(f"â€¢ {suggestion}")
        else:
            st.info("æš‚æ— ç”¨æˆ·åé¦ˆæ•°æ®")
    
    with tab3:
        st.subheader(" å¤šæ¨¡å‹æ”¯æŒ")
        
        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
        available_models = multi_model_manager.list_available_models()
        st.write(f"**å¯ç”¨æ¨¡å‹:** {', '.join(available_models)}")
        
        # æ¨¡å‹ä¿¡æ¯
        selected_model = st.selectbox("é€‰æ‹©æ¨¡å‹æŸ¥çœ‹è¯¦æƒ…", available_models)
        
        if selected_model:
            model_info = multi_model_manager.get_model_info(selected_model)
            
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"**æä¾›å•†:** {model_info.get('provider', 'æœªçŸ¥')}")
                st.write(f"**æœ€å¤§Token:** {model_info.get('max_tokens', 'æœªçŸ¥')}")
            
            with col2:
                st.write(f"**æ”¯æŒå‡½æ•°è°ƒç”¨:** {'æ˜¯' if model_info.get('supports_function_calling') else 'å¦'}")
                st.write(f"**æ”¯æŒæµå¼è¾“å‡º:** {'æ˜¯' if model_info.get('supports_streaming') else 'å¦'}")
        
        # æ¨¡å‹å¯¹æ¯”æµ‹è¯•
        if st.button("è¿è¡Œæ¨¡å‹å¯¹æ¯”"):
            test_question = "è¯·ç®€è¦è§£é‡Šäººå·¥æ™ºèƒ½çš„æ¦‚å¿µ"
            
            with st.spinner("è¿è¡Œæ¨¡å‹å¯¹æ¯”æµ‹è¯•..."):
                try:
                    # åªæ¯”è¾ƒå‰ä¸¤ä¸ªå¯ç”¨æ¨¡å‹
                    test_models = available_models[:2]
                    results = multi_model_manager.compare_models(test_question, test_models)
                    
                    st.write("**å¯¹æ¯”ç»“æœ:**")
                    for model, result in results.items():
                        with st.expander(f"{model}"):
                            if "error" not in result:
                                st.write(result["content"])
                                st.caption(f"ç”¨æ—¶: {result['response_time']:.2f}ç§’ | Token: {result['tokens_used']}")
                            else:
                                st.error(f"é”™è¯¯: {result['error']}")
                
                except Exception as e:
                    st.error(f"æ¨¡å‹å¯¹æ¯”å¤±è´¥: {e}")

def display_system_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    with st.sidebar:
        st.header("ç³»ç»ŸçŠ¶æ€")
        
        # æ•°æ®åº“è¿æ¥çŠ¶æ€
        try:
            session = db_manager.get_session()
            session.close()
            db_status = "é«˜ æ­£å¸¸"
        except:
            db_status = "ä½ å¼‚å¸¸"
        
        st.write(f"**æ•°æ®åº“:** {db_status}")
        
        # å‘é‡åº“çŠ¶æ€
        try:
            vector_count = vector_store.collection.count()
            vector_status = f"é«˜ æ­£å¸¸ ({vector_count} å‘é‡)"
        except:
            vector_status = "ä½ å¼‚å¸¸"
        
        st.write(f"**å‘é‡åº“:** {vector_status}")
        
        # æ¨¡å‹çŠ¶æ€
        model_status = "é«˜ æ­£å¸¸" if multi_model_manager.default_provider else "ä½ å¼‚å¸¸"
        st.write(f"**LLMæ¨¡å‹:** {model_status}")
        
        st.write(f"**å½“å‰æ¨¡å‹:** {st.session_state.selected_model}")
        st.write(f"**RAGæ–¹æ³•:** {st.session_state.rag_method}")
        
        # ä¼šè¯ä¿¡æ¯
        st.write(f"**ä¼šè¯ID:** {st.session_state.session_id}")
        st.write(f"**æ¶ˆæ¯æ•°:** {len(st.session_state.chat_history)}")

def main():
    """ä¸»å‡½æ•°"""
    # åˆå§‹åŒ–
    initialize_session_state()
    
    # æ ‡é¢˜
    st.title(" RAGLite - æ™ºèƒ½é—®ç­”åŠ©æ‰‹")
    st.caption("åŸºäºLangChainä¸MySQLçš„ä¼ä¸šçº§RAGç³»ç»Ÿ")
    
    # ä¾§è¾¹æ å¯¼èˆª
    with st.sidebar:
        st.header("ğŸ§­ å¯¼èˆª")
        page = st.radio(
            "é€‰æ‹©åŠŸèƒ½",
            ["æ™ºèƒ½é—®ç­”", "æ–‡æ¡£ç®¡ç†", "ç³»ç»Ÿè¯„æµ‹"],
            index=0
        )
    
    # æ˜¾ç¤ºå¯¹åº”é¡µé¢
    if page == "æ™ºèƒ½é—®ç­”":
        display_chat_interface()
        display_comparison_interface()
    elif page == "æ–‡æ¡£ç®¡ç†":
        display_document_management()
    elif page == "ç³»ç»Ÿè¯„æµ‹":
        display_evaluation_panel()
    
    # ç³»ç»ŸçŠ¶æ€
    display_system_status()
    
    # é¡µè„š
    st.markdown("---")
    st.markdown(
        "**RAGLite** | "
        "æ”¯æŒå¤šç§RAGæ–¹æ³• | "
        "è‡ªåŠ¨åŒ–è¯„æµ‹ | "
        "ç”¨æˆ·åé¦ˆå­¦ä¹  | "
        " å¤šæ¨¡å‹æ”¯æŒ"
    )

if __name__ == "__main__":
    main()
